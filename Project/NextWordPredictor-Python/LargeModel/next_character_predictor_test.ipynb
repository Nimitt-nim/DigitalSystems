{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {' ': 0,\n",
    " '&': 1,\n",
    " \"'\": 2,\n",
    " '(': 3,\n",
    " ')': 4,\n",
    " ',': 5,\n",
    " '-': 6,\n",
    " '.': 7,\n",
    " '/': 8,\n",
    " '0': 9,\n",
    " '1': 10,\n",
    " '2': 11,\n",
    " '3': 12,\n",
    " '4': 13,\n",
    " '5': 14,\n",
    " '6': 15,\n",
    " '7': 16,\n",
    " '8': 17,\n",
    " '9': 18,\n",
    " ':': 19,\n",
    " ';': 20,\n",
    " '[': 21,\n",
    " ']': 22,\n",
    " 'a': 23,\n",
    " 'b': 24,\n",
    " 'c': 25,\n",
    " 'd': 26,\n",
    " 'e': 27,\n",
    " 'f': 28,\n",
    " 'g': 29,\n",
    " 'h': 30,\n",
    " 'i': 31,\n",
    " 'j': 32,\n",
    " 'k': 33,\n",
    " 'l': 34,\n",
    " 'm': 35,\n",
    " 'n': 36,\n",
    " 'o': 37,\n",
    " 'p': 38,\n",
    " 'q': 39,\n",
    " 'r': 40,\n",
    " 's': 41,\n",
    " 't': 42,\n",
    " 'u': 43,\n",
    " 'v': 44,\n",
    " 'w': 45,\n",
    " 'x': 46,\n",
    " 'y': 47,\n",
    " 'z': 48,\n",
    " '|': 49,\n",
    " '~': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {0: ' ',\n",
    " 1: '&',\n",
    " 2: \"'\",\n",
    " 3: '(',\n",
    " 4: ')',\n",
    " 5: ',',\n",
    " 6: '-',\n",
    " 7: '.',\n",
    " 8: '/',\n",
    " 9: '0',\n",
    " 10: '1',\n",
    " 11: '2',\n",
    " 12: '3',\n",
    " 13: '4',\n",
    " 14: '5',\n",
    " 15: '6',\n",
    " 16: '7',\n",
    " 17: '8',\n",
    " 18: '9',\n",
    " 19: ':',\n",
    " 20: ';',\n",
    " 21: '[',\n",
    " 22: ']',\n",
    " 23: 'a',\n",
    " 24: 'b',\n",
    " 25: 'c',\n",
    " 26: 'd',\n",
    " 27: 'e',\n",
    " 28: 'f',\n",
    " 29: 'g',\n",
    " 30: 'h',\n",
    " 31: 'i',\n",
    " 32: 'j',\n",
    " 33: 'k',\n",
    " 34: 'l',\n",
    " 35: 'm',\n",
    " 36: 'n',\n",
    " 37: 'o',\n",
    " 38: 'p',\n",
    " 39: 'q',\n",
    " 40: 'r',\n",
    " 41: 's',\n",
    " 42: 't',\n",
    " 43: 'u',\n",
    " 44: 'v',\n",
    " 45: 'w',\n",
    " 46: 'x',\n",
    " 47: 'y',\n",
    " 48: 'z',\n",
    " 49: '|',\n",
    " 50: '~'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Forget Gate\n",
    "        self.wf = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bf = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.wi = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bi = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Candidate Gate\n",
    "        self.wc = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bc = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Output Gate\n",
    "        self.wo = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bo = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Final Gate\n",
    "        self.wy = nn.Parameter(torch.Tensor(output_size, hidden_size))\n",
    "        self.by = nn.Parameter(torch.Tensor(output_size, 1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        # Initialize weights with Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.wf)\n",
    "        nn.init.xavier_uniform_(self.wi)\n",
    "        nn.init.xavier_uniform_(self.wc)\n",
    "        nn.init.xavier_uniform_(self.wo)\n",
    "        nn.init.xavier_uniform_(self.wy)\n",
    "\n",
    "        # Initialize biases to zeros\n",
    "        nn.init.constant_(self.bf, 0)\n",
    "        nn.init.constant_(self.bi, 0)\n",
    "        nn.init.constant_(self.bc, 0)\n",
    "        nn.init.constant_(self.bo, 0)\n",
    "        nn.init.constant_(self.by, 0)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        outputs = []\n",
    "        seq_length = X.size(0)\n",
    "        hidden_state = torch.zeros(self.hidden_size,1,dtype=torch.float32)\n",
    "        cell_state = torch.zeros(self.hidden_size,1,dtype = torch.float32)\n",
    "\n",
    "        for q in range(seq_length):\n",
    "            concat_input = torch.cat((hidden_state, X[q].unsqueeze(1)), dim=0)\n",
    "            forget_gate = torch.sigmoid(torch.matmul(self.wf, concat_input) + self.bf)\n",
    "            input_gate = torch.sigmoid(torch.matmul(self.wi, concat_input) + self.bi)\n",
    "            candidate_gate = torch.tanh(torch.matmul(self.wc, concat_input) + self.bc)\n",
    "            output_gate = torch.sigmoid(torch.matmul(self.wo, concat_input) + self.bo)\n",
    "\n",
    "            cell_state = forget_gate * cell_state + input_gate * candidate_gate\n",
    "            hidden_state = output_gate * torch.tanh(cell_state)\n",
    "\n",
    "            output = torch.matmul(self.wy, hidden_state) + self.by\n",
    "            outputs.append(output)\n",
    "        outputs = torch.stack(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out = [self.forward(x) for x in X]\n",
    "        return torch.stack(out)\n",
    "    \n",
    "    def train(self, X, y, epochs, lr, model_path):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            prediction = self.predict(X)\n",
    "            prediction = prediction.reshape(-1, self.output_size)\n",
    "            target = y.reshape(-1)\n",
    "            loss = criterion(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "            current_loss = epoch_loss / len(X)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {current_loss:.4f}\")\n",
    "\n",
    "            if (epoch % 100 == 0):\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': self.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': loss,\n",
    "                            }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 51\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| basic proble advisory 5 8 (version 1.0, november  2022 |\n"
     ]
    }
   ],
   "source": [
    "model_read = LSTM(input_size+hidden_size, hidden_size, input_size)\n",
    "model_path = \"/Users/nimitt/Documents/DigitalSystems/Project/NextWordPredictor-Python/LargeModelStates/model_10_50_5000.pt\"\n",
    "checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model_read.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Testing\n",
    "\n",
    "def convert_to_X(prompt):\n",
    "    X_ = np.zeros((len(prompt),input_size))\n",
    "    for i in range(len(prompt)):\n",
    "        X_[i][stoi[prompt[i]]] = 1\n",
    "    return torch.tensor(X_,dtype = torch.float32)\n",
    "        \n",
    "prompt = \"basi\"\n",
    "max_len = 50\n",
    "context = []\n",
    "for j in range(len(prompt)):\n",
    "    context = context + [stoi[prompt[j]]]\n",
    "context = context[-block_size:]\n",
    "\n",
    "generated_text = prompt\n",
    "for i in range(max_len):\n",
    "    x = convert_to_X(generated_text)\n",
    "    y_pred = model_read(x)[-1]\n",
    "    # ix = torch.distributions.categorical.Categorical(logits=y_pred.squeeze()).sample()\n",
    "    ix = torch.argmax(y_pred)\n",
    "    ch = itos[ix.item()]\n",
    "    generated_text += ch\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "genrated_text = generated_text.replace('|','\\n')\n",
    "print(\"|\",generated_text,\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
