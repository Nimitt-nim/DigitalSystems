{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "with open('/Users/nimitt/Documents/DigitalSystems/Project/Datasets/advisories.txt','r') as file:\n",
    "    text = file.read()\n",
    "text = text.lower()\n",
    "\n",
    "chars = ['\\x00',\n",
    " '\\t',\n",
    " '\\n',\n",
    " ' ',\n",
    " '!',\n",
    " '\"',\n",
    " '#',\n",
    " '$',\n",
    " '%',\n",
    " '&',\n",
    " \"'\",\n",
    " '(',\n",
    " ')',\n",
    " '*',\n",
    " '+',\n",
    " ',',\n",
    " '-',\n",
    " '.',\n",
    " '/',\n",
    " '0',\n",
    " '1',\n",
    " '2',\n",
    " '3',\n",
    " '4',\n",
    " '5',\n",
    " '6',\n",
    " '7',\n",
    " '8',\n",
    " '9',\n",
    " ':',\n",
    " ';',\n",
    " '<',\n",
    " '=',\n",
    " '>',\n",
    " '?',\n",
    " '@',\n",
    " '[',\n",
    " ']',\n",
    " '^',\n",
    " '_',\n",
    " '`',\n",
    " 'a',\n",
    " 'b',\n",
    " 'c',\n",
    " 'd',\n",
    " 'e',\n",
    " 'f',\n",
    " 'g',\n",
    " 'h',\n",
    " 'i',\n",
    " 'j',\n",
    " 'k',\n",
    " 'l',\n",
    " 'm',\n",
    " 'n',\n",
    " 'o',\n",
    " 'p',\n",
    " 'q',\n",
    " 'r',\n",
    " 's',\n",
    " 't',\n",
    " 'u',\n",
    " 'v',\n",
    " 'w',\n",
    " 'x',\n",
    " 'y',\n",
    " 'z',\n",
    " '~',\n",
    " '\\xa0',\n",
    " '¬ß',\n",
    " '¬∑',\n",
    " '‡§Ç',\n",
    " '‡§ï',\n",
    " '‡§ó',\n",
    " '‡§§',\n",
    " '‡§•',\n",
    " '‡§¶',\n",
    " '‡§ß',\n",
    " '‡§®',\n",
    " '‡§™',\n",
    " '‡§≠',\n",
    " '‡§Ø',\n",
    " '‡§∞',\n",
    " '‡§∏',\n",
    " '‡§æ',\n",
    " '‡§ø',\n",
    " '‡•Ä',\n",
    " '‡•ã',\n",
    " '‡•å',\n",
    " '‡•ç',\n",
    " '‚Äì',\n",
    " '‚Äò',\n",
    " '‚Äô',\n",
    " '‚Äú',\n",
    " '‚Äù',\n",
    " '‚Äû',\n",
    " '‚Äü',\n",
    " '‚Ä¢',\n",
    " '‚Ä¶',\n",
    " '\\u2028',\n",
    " '‚Çπ',\n",
    " '‚Üí',\n",
    " '‚àë',\n",
    " '‚àö',\n",
    " '‚â•',\n",
    " '‚ñ°',\n",
    " '‚ñ™',\n",
    " '‚óã',\n",
    " '‚óè',\n",
    " '‚û¢',\n",
    " '\\uf020',\n",
    " '\\uf02d',\n",
    " '\\uf0a7',\n",
    " '\\uf0b7',\n",
    " '\\uf0d8',\n",
    " '\\uf0fc',\n",
    " 'Ô¨Ä',\n",
    " 'Ô¨Å',\n",
    " 'Ô¨É',\n",
    " 'ùê∂',\n",
    " 'ùêº',\n",
    " 'ùëÉ',\n",
    " 'ùëÜ',\n",
    " 'ùëê',\n",
    " 'ùëî']\n",
    "\n",
    "#  Removing unwanted chars\n",
    "unwanted_chars = chars[68:]\n",
    "for unwanted_char in unwanted_chars:\n",
    "    if (unwanted_char in ['‚Ä¢',\n",
    "                            '‚Ä¶',\n",
    "                            '\\u2028',\n",
    "                            '‚Çπ',\n",
    "                            '‚Üí',\n",
    "                            '‚àë','‚àö','‚â•','‚ñ°','‚ñ™','‚óã','‚óè','‚û¢','\\uf020','\\uf02d','\\uf0a7','\\uf0b7','\\uf0d8','\\uf0fc',]):\n",
    "        text = text.replace(unwanted_char,\"|\")\n",
    "    elif (unwanted_char in [ '‚Äò',\n",
    " '‚Äô',\n",
    " '‚Äú',\n",
    " '‚Äù',\n",
    " '‚Äû',\n",
    " '‚Äü',]):\n",
    "        text = text.replace(unwanted_char,\"'\")\n",
    "    else:\n",
    "        text = text.replace(unwanted_char,\"~\")\n",
    "text = text.replace('\\n',\"~\")\n",
    "text = text.replace('\\t',\"~\")\n",
    "text = text.replace('\\x00',\"~\")\n",
    "text_len = 5000\n",
    "text = text[:text_len]\n",
    "# Vocabulary\n",
    "chars = sorted(set(text))   \n",
    "\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "# Creating X and Y\n",
    "X, Y = [],[]\n",
    "context = []\n",
    "for j in range(block_size):\n",
    "    context = context + [stoi[text[j]]]\n",
    "\n",
    "for i in range(block_size, len(text)-1):\n",
    "\n",
    "    X_ = np.zeros((block_size,len(chars)))\n",
    "\n",
    "    for j in range(block_size):\n",
    "        X_[j][context[j]] = 1\n",
    "\n",
    "    ch = text[i]\n",
    "    ix = stoi[ch]\n",
    "\n",
    "\n",
    "    X.append(X_)\n",
    "    \n",
    "    context = context[1:] + [ix] \n",
    "    Y.append(context)\n",
    "\n",
    "X = torch.tensor(np.array(X),dtype=torch.float32)\n",
    "Y = torch.tensor(np.array(Y),dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '&': 1,\n",
       " \"'\": 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " '/': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '6': 15,\n",
       " '7': 16,\n",
       " '8': 17,\n",
       " '9': 18,\n",
       " ':': 19,\n",
       " ';': 20,\n",
       " '[': 21,\n",
       " ']': 22,\n",
       " 'a': 23,\n",
       " 'b': 24,\n",
       " 'c': 25,\n",
       " 'd': 26,\n",
       " 'e': 27,\n",
       " 'f': 28,\n",
       " 'g': 29,\n",
       " 'h': 30,\n",
       " 'i': 31,\n",
       " 'j': 32,\n",
       " 'k': 33,\n",
       " 'l': 34,\n",
       " 'm': 35,\n",
       " 'n': 36,\n",
       " 'o': 37,\n",
       " 'p': 38,\n",
       " 'q': 39,\n",
       " 'r': 40,\n",
       " 's': 41,\n",
       " 't': 42,\n",
       " 'u': 43,\n",
       " 'v': 44,\n",
       " 'w': 45,\n",
       " 'x': 46,\n",
       " 'y': 47,\n",
       " 'z': 48,\n",
       " '|': 49,\n",
       " '~': 50}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Forget Gate\n",
    "        self.wf = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bf = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.wi = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bi = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Candidate Gate\n",
    "        self.wc = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bc = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Output Gate\n",
    "        self.wo = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bo = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Final Gate\n",
    "        self.wy = nn.Parameter(torch.Tensor(output_size, hidden_size))\n",
    "        self.by = nn.Parameter(torch.Tensor(output_size, 1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        # Initialize weights with Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.wf)\n",
    "        nn.init.xavier_uniform_(self.wi)\n",
    "        nn.init.xavier_uniform_(self.wc)\n",
    "        nn.init.xavier_uniform_(self.wo)\n",
    "        nn.init.xavier_uniform_(self.wy)\n",
    "\n",
    "        # Initialize biases to zeros\n",
    "        nn.init.constant_(self.bf, 0)\n",
    "        nn.init.constant_(self.bi, 0)\n",
    "        nn.init.constant_(self.bc, 0)\n",
    "        nn.init.constant_(self.bo, 0)\n",
    "        nn.init.constant_(self.by, 0)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        outputs = []\n",
    "        seq_length = X.size(0)\n",
    "        hidden_state = torch.zeros(self.hidden_size,1,dtype=torch.float32)\n",
    "        cell_state = torch.zeros(self.hidden_size,1,dtype = torch.float32)\n",
    "\n",
    "        for q in range(seq_length):\n",
    "            concat_input = torch.cat((hidden_state, X[q].unsqueeze(1)), dim=0)\n",
    "            forget_gate = torch.sigmoid(torch.matmul(self.wf, concat_input) + self.bf)\n",
    "            input_gate = torch.sigmoid(torch.matmul(self.wi, concat_input) + self.bi)\n",
    "            candidate_gate = torch.tanh(torch.matmul(self.wc, concat_input) + self.bc)\n",
    "            output_gate = torch.sigmoid(torch.matmul(self.wo, concat_input) + self.bo)\n",
    "\n",
    "            cell_state = forget_gate * cell_state + input_gate * candidate_gate\n",
    "            hidden_state = output_gate * torch.tanh(cell_state)\n",
    "\n",
    "            output = torch.matmul(self.wy, hidden_state) + self.by\n",
    "            outputs.append(output)\n",
    "        outputs = torch.stack(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out = [self.forward(x) for x in X]\n",
    "        return torch.stack(out)\n",
    "    \n",
    "    def train(self, X, y, epochs, lr, model_path):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            prediction = self.predict(X)\n",
    "            prediction = prediction.reshape(-1, self.output_size)\n",
    "            target = y.reshape(-1)\n",
    "            loss = criterion(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "            current_loss = epoch_loss / len(X)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {current_loss:.4f}\")\n",
    "\n",
    "            if (epoch % 100 == 0):\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': self.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': loss,\n",
    "                            }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 51\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = len(chars)\n",
    "\n",
    "# model = LSTM(hidden_size+input_size, hidden_size, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "\n",
    "# checkpoint_folder = \"/Users/nimitt/Documents/DigitalSystems/Project/Model_States\"\n",
    "# model_filename = f\"model_{block_size}_{hidden_size}_{text_len}.pt\"\n",
    "# model_path = os.path.join(checkpoint_folder, model_filename)\n",
    "# # Ensure the folder exists\n",
    "# os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "# model.train(X,Y,500,0.01,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alumni                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "# # Testing\n",
    "\n",
    "# def convert_to_X(prompt):\n",
    "#     X_ = np.zeros((len(prompt),input_size))\n",
    "#     for i in range(len(prompt)):\n",
    "#         X_[i][stoi[prompt[i]]] = 1\n",
    "#     return torch.tensor(X_,dtype = torch.float32)\n",
    "        \n",
    "# prompt = \"alumni\"\n",
    "# max_len = 100\n",
    "# context = []\n",
    "# for j in range(len(prompt)):\n",
    "#     context = context + [stoi[prompt[j]]]\n",
    "# context = context[-block_size:]\n",
    "\n",
    "# generated_text = prompt\n",
    "# for i in range(max_len):\n",
    "#     x = convert_to_X(generated_text)\n",
    "#     y_pred = model(x)[-1]\n",
    "#     # ix = torch.distributions.categorical.Categorical(logits=y_pred.squeeze()).sample()\n",
    "#     ix = torch.argmax(y_pred)\n",
    "#     ch = itos[ix.item()]\n",
    "#     generated_text += ch\n",
    "#     context = context[1:] + [ix]\n",
    "\n",
    "# genrated_text = generated_text.replace('|','\\n')\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alumni relations advisory 02 (version 1.0, december 2021)                                 page 1 of 1 ~ indian institute of technology gandhinagar  ~ ~honorary  alumni program at iit gandhinagar  ~(as approved by the bog in its 33rd meeting held on 15 november 2021)  ~ ~ ~the board of governors of the institute in its 33rd meeting held on 15 november ~2021 approved the following honorary alumni program  at iit gandhinagar.  ~  ~1. individuals who are not graduates of iit gandhinagar and who make'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| basic proble advisory 5 8 (version 1.0, november  2022 |\n"
     ]
    }
   ],
   "source": [
    "model_read = LSTM(input_size+hidden_size, hidden_size, input_size)\n",
    "model_path = \"/Users/nimitt/Documents/DigitalSystems/Project/Model_States/model_10_50_5000.pt\"\n",
    "checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model_read.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Testing\n",
    "\n",
    "def convert_to_X(prompt):\n",
    "    X_ = np.zeros((len(prompt),input_size))\n",
    "    for i in range(len(prompt)):\n",
    "        X_[i][stoi[prompt[i]]] = 1\n",
    "    return torch.tensor(X_,dtype = torch.float32)\n",
    "        \n",
    "prompt = \"basi\"\n",
    "max_len = 50\n",
    "context = []\n",
    "for j in range(len(prompt)):\n",
    "    context = context + [stoi[prompt[j]]]\n",
    "context = context[-block_size:]\n",
    "\n",
    "generated_text = prompt\n",
    "for i in range(max_len):\n",
    "    x = convert_to_X(generated_text)\n",
    "    y_pred = model_read(x)[-1]\n",
    "    # ix = torch.distributions.categorical.Categorical(logits=y_pred.squeeze()).sample()\n",
    "    ix = torch.argmax(y_pred)\n",
    "    ch = itos[ix.item()]\n",
    "    generated_text += ch\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "genrated_text = generated_text.replace('|','\\n')\n",
    "print(\"|\",generated_text,\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
