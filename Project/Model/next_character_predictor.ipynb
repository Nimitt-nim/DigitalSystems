{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "with open('/Users/nimitt/Documents/DigitalSystems/Project/Datasets/advisories.txt','r') as file:\n",
    "    text = file.read()\n",
    "text = text.lower()\n",
    "\n",
    "chars = ['\\x00',\n",
    " '\\t',\n",
    " '\\n',\n",
    " ' ',\n",
    " '!',\n",
    " '\"',\n",
    " '#',\n",
    " '$',\n",
    " '%',\n",
    " '&',\n",
    " \"'\",\n",
    " '(',\n",
    " ')',\n",
    " '*',\n",
    " '+',\n",
    " ',',\n",
    " '-',\n",
    " '.',\n",
    " '/',\n",
    " '0',\n",
    " '1',\n",
    " '2',\n",
    " '3',\n",
    " '4',\n",
    " '5',\n",
    " '6',\n",
    " '7',\n",
    " '8',\n",
    " '9',\n",
    " ':',\n",
    " ';',\n",
    " '<',\n",
    " '=',\n",
    " '>',\n",
    " '?',\n",
    " '@',\n",
    " '[',\n",
    " ']',\n",
    " '^',\n",
    " '_',\n",
    " '`',\n",
    " 'a',\n",
    " 'b',\n",
    " 'c',\n",
    " 'd',\n",
    " 'e',\n",
    " 'f',\n",
    " 'g',\n",
    " 'h',\n",
    " 'i',\n",
    " 'j',\n",
    " 'k',\n",
    " 'l',\n",
    " 'm',\n",
    " 'n',\n",
    " 'o',\n",
    " 'p',\n",
    " 'q',\n",
    " 'r',\n",
    " 's',\n",
    " 't',\n",
    " 'u',\n",
    " 'v',\n",
    " 'w',\n",
    " 'x',\n",
    " 'y',\n",
    " 'z',\n",
    " '~',\n",
    " '\\xa0',\n",
    " 'Â§',\n",
    " 'Â·',\n",
    " 'à¤‚',\n",
    " 'à¤•',\n",
    " 'à¤—',\n",
    " 'à¤¤',\n",
    " 'à¤¥',\n",
    " 'à¤¦',\n",
    " 'à¤§',\n",
    " 'à¤¨',\n",
    " 'à¤ª',\n",
    " 'à¤­',\n",
    " 'à¤¯',\n",
    " 'à¤°',\n",
    " 'à¤¸',\n",
    " 'à¤¾',\n",
    " 'à¤¿',\n",
    " 'à¥€',\n",
    " 'à¥‹',\n",
    " 'à¥Œ',\n",
    " 'à¥',\n",
    " 'â€“',\n",
    " 'â€˜',\n",
    " 'â€™',\n",
    " 'â€œ',\n",
    " 'â€',\n",
    " 'â€ž',\n",
    " 'â€Ÿ',\n",
    " 'â€¢',\n",
    " 'â€¦',\n",
    " '\\u2028',\n",
    " 'â‚¹',\n",
    " 'â†’',\n",
    " 'âˆ‘',\n",
    " 'âˆš',\n",
    " 'â‰¥',\n",
    " 'â–¡',\n",
    " 'â–ª',\n",
    " 'â—‹',\n",
    " 'â—',\n",
    " 'âž¢',\n",
    " '\\uf020',\n",
    " '\\uf02d',\n",
    " '\\uf0a7',\n",
    " '\\uf0b7',\n",
    " '\\uf0d8',\n",
    " '\\uf0fc',\n",
    " 'ï¬€',\n",
    " 'ï¬',\n",
    " 'ï¬ƒ',\n",
    " 'ð¶',\n",
    " 'ð¼',\n",
    " 'ð‘ƒ',\n",
    " 'ð‘†',\n",
    " 'ð‘',\n",
    " 'ð‘”']\n",
    "\n",
    "#  Removing unwanted chars\n",
    "unwanted_chars = chars[68:]\n",
    "for unwanted_char in unwanted_chars:\n",
    "    if (unwanted_char in ['â€¢',\n",
    "                            'â€¦',\n",
    "                            '\\u2028',\n",
    "                            'â‚¹',\n",
    "                            'â†’',\n",
    "                            'âˆ‘','âˆš','â‰¥','â–¡','â–ª','â—‹','â—','âž¢','\\uf020','\\uf02d','\\uf0a7','\\uf0b7','\\uf0d8','\\uf0fc',]):\n",
    "        text = text.replace(unwanted_char,\"|\")\n",
    "    elif (unwanted_char in [ 'â€˜',\n",
    " 'â€™',\n",
    " 'â€œ',\n",
    " 'â€',\n",
    " 'â€ž',\n",
    " 'â€Ÿ',]):\n",
    "        text = text.replace(unwanted_char,\"'\")\n",
    "    else:\n",
    "        text = text.replace(unwanted_char,\"~\")\n",
    "text = text.replace('\\n',\"~\")\n",
    "text = text.replace('\\t',\"~\")\n",
    "text = text.replace('\\x00',\"~\")\n",
    "text_len = 5000\n",
    "text = text[:text_len]\n",
    "# Vocabulary\n",
    "chars = sorted(set(text))   \n",
    "\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "# Creating X and Y\n",
    "X, Y = [],[]\n",
    "context = []\n",
    "for j in range(block_size):\n",
    "    context = context + [stoi[text[j]]]\n",
    "\n",
    "for i in range(block_size, len(text)-1):\n",
    "\n",
    "    X_ = np.zeros((block_size,len(chars)))\n",
    "\n",
    "    for j in range(block_size):\n",
    "        X_[j][context[j]] = 1\n",
    "\n",
    "    ch = text[i]\n",
    "    ix = stoi[ch]\n",
    "\n",
    "\n",
    "    X.append(X_)\n",
    "    \n",
    "    context = context[1:] + [ix] \n",
    "    Y.append(context)\n",
    "\n",
    "X = torch.tensor(np.array(X),dtype=torch.float32)\n",
    "Y = torch.tensor(np.array(Y),dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '&': 1,\n",
       " \"'\": 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " '/': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '6': 15,\n",
       " '7': 16,\n",
       " '8': 17,\n",
       " '9': 18,\n",
       " ':': 19,\n",
       " ';': 20,\n",
       " '[': 21,\n",
       " ']': 22,\n",
       " 'a': 23,\n",
       " 'b': 24,\n",
       " 'c': 25,\n",
       " 'd': 26,\n",
       " 'e': 27,\n",
       " 'f': 28,\n",
       " 'g': 29,\n",
       " 'h': 30,\n",
       " 'i': 31,\n",
       " 'j': 32,\n",
       " 'k': 33,\n",
       " 'l': 34,\n",
       " 'm': 35,\n",
       " 'n': 36,\n",
       " 'o': 37,\n",
       " 'p': 38,\n",
       " 'q': 39,\n",
       " 'r': 40,\n",
       " 's': 41,\n",
       " 't': 42,\n",
       " 'u': 43,\n",
       " 'v': 44,\n",
       " 'w': 45,\n",
       " 'x': 46,\n",
       " 'y': 47,\n",
       " 'z': 48,\n",
       " '|': 49,\n",
       " '~': 50}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Forget Gate\n",
    "        self.wf = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bf = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.wi = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bi = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Candidate Gate\n",
    "        self.wc = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bc = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Output Gate\n",
    "        self.wo = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
    "        self.bo = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "\n",
    "        # Final Gate\n",
    "        self.wy = nn.Parameter(torch.Tensor(output_size, hidden_size))\n",
    "        self.by = nn.Parameter(torch.Tensor(output_size, 1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        # Initialize weights with Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.wf)\n",
    "        nn.init.xavier_uniform_(self.wi)\n",
    "        nn.init.xavier_uniform_(self.wc)\n",
    "        nn.init.xavier_uniform_(self.wo)\n",
    "        nn.init.xavier_uniform_(self.wy)\n",
    "\n",
    "        # Initialize biases to zeros\n",
    "        nn.init.constant_(self.bf, 0)\n",
    "        nn.init.constant_(self.bi, 0)\n",
    "        nn.init.constant_(self.bc, 0)\n",
    "        nn.init.constant_(self.bo, 0)\n",
    "        nn.init.constant_(self.by, 0)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        outputs = []\n",
    "        seq_length = X.size(0)\n",
    "        hidden_state = torch.zeros(self.hidden_size,1,dtype=torch.float32)\n",
    "        cell_state = torch.zeros(self.hidden_size,1,dtype = torch.float32)\n",
    "\n",
    "        for q in range(seq_length):\n",
    "            concat_input = torch.cat((hidden_state, X[q].unsqueeze(1)), dim=0)\n",
    "            forget_gate = torch.sigmoid(torch.matmul(self.wf, concat_input) + self.bf)\n",
    "            input_gate = torch.sigmoid(torch.matmul(self.wi, concat_input) + self.bi)\n",
    "            candidate_gate = torch.tanh(torch.matmul(self.wc, concat_input) + self.bc)\n",
    "            output_gate = torch.sigmoid(torch.matmul(self.wo, concat_input) + self.bo)\n",
    "\n",
    "            cell_state = forget_gate * cell_state + input_gate * candidate_gate\n",
    "            hidden_state = output_gate * torch.tanh(cell_state)\n",
    "\n",
    "            output = torch.matmul(self.wy, hidden_state) + self.by\n",
    "            outputs.append(output)\n",
    "        outputs = torch.stack(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out = [self.forward(x) for x in X]\n",
    "        return torch.stack(out)\n",
    "    \n",
    "    def train(self, X, y, epochs, lr, model_path):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            prediction = self.predict(X)\n",
    "            prediction = prediction.reshape(-1, self.output_size)\n",
    "            target = y.reshape(-1)\n",
    "            loss = criterion(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "            current_loss = epoch_loss / len(X)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {current_loss:.4f}\")\n",
    "\n",
    "            if (epoch % 100 == 0):\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': self.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': loss,\n",
    "                            }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "input_size = len(chars)\n",
    "\n",
    "model = LSTM(hidden_size+input_size, hidden_size, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 0.0008\n",
      "Epoch 2/500, Loss: 0.0008\n",
      "Epoch 3/500, Loss: 0.0008\n",
      "Epoch 4/500, Loss: 0.0008\n",
      "Epoch 5/500, Loss: 0.0008\n",
      "Epoch 6/500, Loss: 0.0007\n",
      "Epoch 7/500, Loss: 0.0007\n",
      "Epoch 8/500, Loss: 0.0007\n",
      "Epoch 9/500, Loss: 0.0007\n",
      "Epoch 10/500, Loss: 0.0007\n",
      "Epoch 11/500, Loss: 0.0007\n",
      "Epoch 12/500, Loss: 0.0006\n",
      "Epoch 13/500, Loss: 0.0006\n",
      "Epoch 14/500, Loss: 0.0006\n",
      "Epoch 15/500, Loss: 0.0006\n",
      "Epoch 16/500, Loss: 0.0006\n",
      "Epoch 17/500, Loss: 0.0006\n",
      "Epoch 18/500, Loss: 0.0006\n",
      "Epoch 19/500, Loss: 0.0006\n",
      "Epoch 20/500, Loss: 0.0006\n",
      "Epoch 21/500, Loss: 0.0006\n",
      "Epoch 22/500, Loss: 0.0006\n",
      "Epoch 23/500, Loss: 0.0006\n",
      "Epoch 24/500, Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "checkpoint_folder = \"/Users/nimitt/Documents/DigitalSystems/Project/Model_States\"\n",
    "model_filename = f\"model_{block_size}_{hidden_size}_{text_len}.pt\"\n",
    "model_path = os.path.join(checkpoint_folder, model_filename)\n",
    "# Ensure the folder exists\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "model.train(X,Y,500,0.01,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the thing istitute in its 33rd meeting held on 15 november 2021)  ~ ~ ~the board of governors of the institute o\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "def convert_to_X(prompt):\n",
    "    X_ = np.zeros((len(prompt),input_size))\n",
    "    for i in range(len(prompt)):\n",
    "        X_[i][stoi[prompt[i]]] = 1\n",
    "    return torch.tensor(X_,dtype = torch.float32)\n",
    "        \n",
    "prompt = \"the thing is\"\n",
    "max_len = 100\n",
    "context = []\n",
    "for j in range(len(prompt)):\n",
    "    context = context + [stoi[prompt[j]]]\n",
    "context = context[-block_size:]\n",
    "\n",
    "generated_text = prompt\n",
    "for i in range(max_len):\n",
    "    x = convert_to_X(generated_text)\n",
    "    y_pred = model(x)[-1]\n",
    "    # ix = torch.distributions.categorical.Categorical(logits=y_pred.squeeze()).sample()\n",
    "    ix = torch.argmax(y_pred)\n",
    "    ch = itos[ix.item()]\n",
    "    generated_text += ch\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "genrated_text = generated_text.replace('|','\\n')\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alumni relations advisory 02 (version 1.0, december 2021)                                 page 1 of 1 ~ indian institute of technology gandhinagar  ~ ~honorary  alumni program at iit gandhinagar  ~(as approved by the bog in its 33rd meeting held on 15 november 2021)  ~ ~ ~the board of governors of the institute in its 33rd meeting held on 15 november ~2021 approved the following honorary alumni program  at iit gandhinagar.  ~  ~1. individuals who are not graduates of iit gandhinagar and who make'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 18483\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_read = LSTM(input_size+hidden_size, hidden_size, input_size)\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "model_path = \"/Users/nimitt/Documents/DigitalSystems/Project/Model_States/model_10_50.pt\"\n",
    "checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model_read.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m context \u001b[39m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(prompt)):\n\u001b[0;32m---> 13\u001b[0m     context \u001b[39m=\u001b[39m context \u001b[39m+\u001b[39m [stoi[prompt[j]]]\n\u001b[1;32m     14\u001b[0m context \u001b[39m=\u001b[39m context[\u001b[39m-\u001b[39mblock_size:]\n\u001b[1;32m     16\u001b[0m generated_text \u001b[39m=\u001b[39m prompt\n",
      "\u001b[0;31mKeyError\u001b[0m: 'j'"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "def convert_to_X(prompt):\n",
    "    X_ = np.zeros((len(prompt),input_size))\n",
    "    for i in range(len(prompt)):\n",
    "        X_[i][stoi[prompt[i]]] = 1\n",
    "    return torch.tensor(X_,dtype = torch.float32)\n",
    "        \n",
    "prompt = \"jason\"\n",
    "max_len = 100\n",
    "context = []\n",
    "for j in range(len(prompt)):\n",
    "    context = context + [stoi[prompt[j]]]\n",
    "context = context[-block_size:]\n",
    "\n",
    "generated_text = prompt\n",
    "for i in range(max_len):\n",
    "    x = convert_to_X(generated_text)\n",
    "    y_pred = model(x)[-1]\n",
    "    # ix = torch.distributions.categorical.Categorical(logits=y_pred.squeeze()).sample()\n",
    "    ix = torch.argmax(y_pred)\n",
    "    ch = itos[ix.item()]\n",
    "    generated_text += ch\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "genrated_text = generated_text.replace('|','\\n')\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
